{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-jD-XYIJazz",
        "colab_type": "text"
      },
      "source": [
        "# **Predicting 3D poses from 2D skeletons**\n",
        "\n",
        "In this tutorial, we are going to train a neural network to take an input 2D skeleton and predict its 3D pose. An schematic view of the framework is presented in the image below.\n",
        "![alt text](https://www.cse.iitb.ac.in/PS-Dataset/martinez_overview.png)\n",
        "\n",
        "The network consists only of FC layers. It uses 2 blocks with residual connection in series. Apart from the input and the output all intermediate layers has 1024 nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic1D3FqLeDpI",
        "colab_type": "code",
        "outputId": "f74ba727-bf45-4f72-e1fd-a4b39dde0deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/rmitra/DLWorkshop-lab1\n",
        "%cd DLWorkshop-lab1/\n",
        "!sh getData.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DLWorkshop-lab1'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 27 (delta 13), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (27/27), done.\n",
            "/content/DLWorkshop-lab1\n",
            "--2020-03-04 09:10:24--  https://www.dropbox.com/s/b20gdo2ywkbx87b/dataset_test_gt.pickle\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/b20gdo2ywkbx87b/dataset_test_gt.pickle [following]\n",
            "--2020-03-04 09:10:24--  https://www.dropbox.com/s/raw/b20gdo2ywkbx87b/dataset_test_gt.pickle\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucf04a04d3c769708b8c00590bbb.dl.dropboxusercontent.com/cd/0/inline/AzSKNeA6_bPhZHQ08XW4hl4SToBtkZaMVS9t0PAXaZRiR98rGud42iWuDNFhE5N4fyl_VXf-U0CNhxWbnmluCirl--An0a7Ti8uMKkotHx-1xVbejtZNjiWILAlL0Jp5Ov8/file# [following]\n",
            "--2020-03-04 09:10:24--  https://ucf04a04d3c769708b8c00590bbb.dl.dropboxusercontent.com/cd/0/inline/AzSKNeA6_bPhZHQ08XW4hl4SToBtkZaMVS9t0PAXaZRiR98rGud42iWuDNFhE5N4fyl_VXf-U0CNhxWbnmluCirl--An0a7Ti8uMKkotHx-1xVbejtZNjiWILAlL0Jp5Ov8/file\n",
            "Resolving ucf04a04d3c769708b8c00590bbb.dl.dropboxusercontent.com (ucf04a04d3c769708b8c00590bbb.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to ucf04a04d3c769708b8c00590bbb.dl.dropboxusercontent.com (ucf04a04d3c769708b8c00590bbb.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AzTq0EM8jRiUrtcOfA5a3x4sYziTIt_kPzdcWmK0GSIaKowqiXJamAF_al2_8zMrOJk93cGddwLrG3IsO5yq7UOGQj-4VWPIiAwsqH9SK2YytS6gsWE_C30EKXBJmjWptFBAbmPkUcgxYNv5a0ltfwMaNXKbXj9pZklzum6EXs0M8Wv0QPQJzFj_lO2xokhq6VgQmEWurFtRq3zDOVkDf_j0kuTLu2OFaYjhROAr-s2aylcdceHl6XcrK19diB8Er6jAlBMTkqiqjjIqzI0gAUFrT6o_PhwfDvOfhHXiOucxr3zHMU8e_YfDhrDY53oo9WSXfWswSl_oczheL2byaU-VYQZerT6Ahz7IF3xHU00qxw/file [following]\n",
            "--2020-03-04 09:10:25--  https://ucf04a04d3c769708b8c00590bbb.dl.dropboxusercontent.com/cd/0/inline2/AzTq0EM8jRiUrtcOfA5a3x4sYziTIt_kPzdcWmK0GSIaKowqiXJamAF_al2_8zMrOJk93cGddwLrG3IsO5yq7UOGQj-4VWPIiAwsqH9SK2YytS6gsWE_C30EKXBJmjWptFBAbmPkUcgxYNv5a0ltfwMaNXKbXj9pZklzum6EXs0M8Wv0QPQJzFj_lO2xokhq6VgQmEWurFtRq3zDOVkDf_j0kuTLu2OFaYjhROAr-s2aylcdceHl6XcrK19diB8Er6jAlBMTkqiqjjIqzI0gAUFrT6o_PhwfDvOfhHXiOucxr3zHMU8e_YfDhrDY53oo9WSXfWswSl_oczheL2byaU-VYQZerT6Ahz7IF3xHU00qxw/file\n",
            "Reusing existing connection to ucf04a04d3c769708b8c00590bbb.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 59207814 (56M) [application/octet-stream]\n",
            "Saving to: ‘dataset_test_gt.pickle’\n",
            "\n",
            "dataset_test_gt.pic 100%[===================>]  56.46M  61.0MB/s    in 0.9s    \n",
            "\n",
            "2020-03-04 09:10:26 (61.0 MB/s) - ‘dataset_test_gt.pickle’ saved [59207814/59207814]\n",
            "\n",
            "--2020-03-04 09:10:26--  https://www.dropbox.com/s/hsqealoayed1grp/dataset_train_gt.pickle\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/hsqealoayed1grp/dataset_train_gt.pickle [following]\n",
            "--2020-03-04 09:10:27--  https://www.dropbox.com/s/raw/hsqealoayed1grp/dataset_train_gt.pickle\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucac086359242703b0068e19bcb4.dl.dropboxusercontent.com/cd/0/inline/AzRrCba8aiKyGODK1G3_lqdF9MAocKvldtnu5pDXLm76pnNO87zO8emKoz-GFYzP_vgaMWT8cGNxbzJCAJ1lGAB7J07F0nR4IBoPp7VqNp0wLSubN0Hb2Bm1i_hjMBoBbqs/file# [following]\n",
            "--2020-03-04 09:10:27--  https://ucac086359242703b0068e19bcb4.dl.dropboxusercontent.com/cd/0/inline/AzRrCba8aiKyGODK1G3_lqdF9MAocKvldtnu5pDXLm76pnNO87zO8emKoz-GFYzP_vgaMWT8cGNxbzJCAJ1lGAB7J07F0nR4IBoPp7VqNp0wLSubN0Hb2Bm1i_hjMBoBbqs/file\n",
            "Resolving ucac086359242703b0068e19bcb4.dl.dropboxusercontent.com (ucac086359242703b0068e19bcb4.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to ucac086359242703b0068e19bcb4.dl.dropboxusercontent.com (ucac086359242703b0068e19bcb4.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AzQcOFb0UNuUppRPzQ8Ue4j12bhXBYXwPGzfCcNKhs687qxrqljsjRTg3UVkaYUnhMmy0u-12ExTt0Yuh7PQMcQhFpNfQSDW7FxMroSPcZ9dhJ5baK2YWyYM8ivi5k9eA9gPpSUQL8q1k5vu5v-suX5rQXJZ7mt-_tMMHXWoSfKHf3oHjHI2YGDBDl9VNw0cPPrqTyOUKcUFaKz3_pl6mr6ybVPdjSB7vwJr6dJPq1XBxG9oFo3ViZcaKooGvKSWSTc7lv1vl_UEyhKxLpzVrGU7R9FgdhoPyj6yQu1uY1PDx2aa2suCO0TUfhM_FWSHy4hWOIUnBxK6I6OeYzxbZ5YrAMco3OGjVDrm65c-mBU4Vg/file [following]\n",
            "--2020-03-04 09:10:27--  https://ucac086359242703b0068e19bcb4.dl.dropboxusercontent.com/cd/0/inline2/AzQcOFb0UNuUppRPzQ8Ue4j12bhXBYXwPGzfCcNKhs687qxrqljsjRTg3UVkaYUnhMmy0u-12ExTt0Yuh7PQMcQhFpNfQSDW7FxMroSPcZ9dhJ5baK2YWyYM8ivi5k9eA9gPpSUQL8q1k5vu5v-suX5rQXJZ7mt-_tMMHXWoSfKHf3oHjHI2YGDBDl9VNw0cPPrqTyOUKcUFaKz3_pl6mr6ybVPdjSB7vwJr6dJPq1XBxG9oFo3ViZcaKooGvKSWSTc7lv1vl_UEyhKxLpzVrGU7R9FgdhoPyj6yQu1uY1PDx2aa2suCO0TUfhM_FWSHy4hWOIUnBxK6I6OeYzxbZ5YrAMco3OGjVDrm65c-mBU4Vg/file\n",
            "Reusing existing connection to ucac086359242703b0068e19bcb4.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169921576 (162M) [application/octet-stream]\n",
            "Saving to: ‘dataset_train_gt.pickle’\n",
            "\n",
            "dataset_train_gt.pi 100%[===================>] 162.05M  50.1MB/s    in 3.2s    \n",
            "\n",
            "2020-03-04 09:10:31 (50.1 MB/s) - ‘dataset_train_gt.pickle’ saved [169921576/169921576]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1gkru1HEYH-",
        "colab_type": "code",
        "outputId": "cd0b9804-83ea-4cc2-8eb2-7d608d705be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "from data_loader import PoseDataset\n",
        "from common.visualizer import show_pred_pose\n",
        "import easydict\n",
        "\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1298f66eb0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5JJwf_WIw3Q",
        "colab_type": "text"
      },
      "source": [
        "<font color=red>In following section, the deep learning model performimng 2D to 3D lifting is described. The image below in the Overview section shows the architecture of a residual block.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDJFeilQ4Baz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PoseModel(nn.Module):\n",
        "    def __init__(self, num_joints_in, in_features, num_joints_out,\n",
        "                 dropout=0.25, channels=1024):\n",
        "        \"\"\"\n",
        "        Initialize this model.\n",
        "\n",
        "        Arguments:\n",
        "        num_joints_in -- number of input joints (e.g. 17 for Human3.6M)\n",
        "        in_features -- number of input features for each joint (typically 2 for 2D input)\n",
        "        num_joints_out -- number of output joints (can be different than input)\n",
        "        dropout -- dropout probability\n",
        "        channels -- no nodes in intermediate layer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_joints_in = num_joints_in\n",
        "        self.in_features = in_features\n",
        "        self.num_joints_out = num_joints_out\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.expand_layer = nn.Linear(num_joints_in * in_features, channels, bias=False)\n",
        "        self.expand_bn = nn.BatchNorm1d(channels, momentum=0.1)\n",
        "        self.shrink = nn.Linear(channels, num_joints_out * 3)\n",
        "\n",
        "        # First block\n",
        "        self.b1_l1 = nn.Linear(channels, channels, bias=False)\n",
        "        self.b1_bn1 = nn.BatchNorm1d(channels, momentum=0.1)\n",
        "        self.b1_l2 = nn.Linear(channels, channels, bias=False)\n",
        "        self.b1_bn2 = nn.BatchNorm1d(channels, momentum=0.1)\n",
        "        \n",
        "        # Second block\n",
        "        self.b2_l1 = nn.Linear(channels, channels, bias=False)\n",
        "        self.b2_bn1 = nn.BatchNorm1d(channels, momentum=0.1)\n",
        "        self.b2_l2 = nn.Linear(channels, channels, bias=False)\n",
        "        self.b2_bn2 = nn.BatchNorm1d(channels, momentum=0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        assert len(x.shape) == 2\n",
        "        assert x.shape[-1] == self.num_joints_in * self.in_features\n",
        "\n",
        "        # Expand from 2D skeleton to 'channels' features \n",
        "        x = self.drop(self.relu(self.expand_bn(self.expand_layer(x)))) # FILL HERE pass through expand linear and BN layer\n",
        "\n",
        "        # First block\n",
        "        res_1 = x\n",
        "        x = self.drop(self.relu(self.b1_bn1(self.b1_l1(x))))\n",
        "        x = self.drop(self.relu(self.b1_bn2(self.b1_l2(x))))\n",
        "        x = x + res_1\n",
        "\n",
        "        # Second block\n",
        "        res_2 = x\n",
        "        x = self.drop(self.relu(self.b2_bn1(self.b2_l1(x))))\n",
        "        x = self.drop(self.relu(self.b2_bn2(self.b2_l2(x))))\n",
        "        x = x + res_2\n",
        "        \n",
        "        x = self.shrink(x) # FILL HERE pass through shrink layer\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA9jhhC9Ns2h",
        "colab_type": "text"
      },
      "source": [
        "<font color=red>The following function is used to calculate both MSE loss for pose regression as well as Mean Per-Joint Position Error(MPJPE) to determine pose prediction accuracy. For MSE, both target and predicted should be of (batch size, num joints * 3). For MPJPE, both target and predicted should be (batch size, num joints, 3).</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKWZBVptIhQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mpjpe(predicted, target):\n",
        "    \"\"\"\n",
        "    Mean per-joint position error (i.e. mean Euclidean distance),\n",
        "    often referred to as \"Protocol #1\" in many papers.\n",
        "    \"\"\"\n",
        "    assert predicted.shape == target.shape\n",
        "    return torch.mean(torch.norm(predicted - target, dim=len(target.shape)-1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z459DGjjOuNu",
        "colab_type": "text"
      },
      "source": [
        "<font color=red>The following function describes the training or test loop for one epoch. It can accept 'train' oe 'test' modes. The boolean parameter 'viz_pred' to display predicted 3D poses.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xyh2tdTEIcKc",
        "colab": {}
      },
      "source": [
        "def run_epoch(epoch, args, model_pose, data_loader, optimiser, mode='train', viz_pred=False):\n",
        "\n",
        "    if mode == 'train':\n",
        "        model_pose.train()\n",
        "    else:\n",
        "        model_pose.eval()\n",
        "\n",
        "    start_time = time()\n",
        "    epoch_loss_3d = 0\n",
        "    mpjpe_epoch = 0.\n",
        "    N = 0\n",
        "\n",
        "    for batch_idx, (pose_2d, pose_3d_rel, _) in enumerate(tqdm(data_loader, ascii=True)):\n",
        "\n",
        "        pose_2d = pose_2d.float()\n",
        "        pose_3d_rel = pose_3d_rel.float()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            pose_2d = pose_2d.cuda()\n",
        "            pose_3d_rel = pose_3d_rel.cuda()\n",
        "\n",
        "        optimiser.zero_grad()\n",
        "\n",
        "        # Predict 3D poses\n",
        "        predicted_3d_pos = model_pose(pose_2d)\n",
        "\n",
        "        if viz_pred is True:\n",
        "            pred_3d_viz = np.zeros((1, 17, 3), dtype='float32')\n",
        "            pred_3d_viz[:, 1:, :] = predicted_3d_pos[0].detach().cpu().view(16, 3).numpy() * 1000\n",
        "            pose_2d_viz = pose_2d[0].cpu().view(1, 17, 2).numpy()\n",
        "\n",
        "            show_pred_pose(pose_2d_viz, pred_3d_viz, n_joints=17)\n",
        "            from IPython.core.debugger import set_trace\n",
        "            set_trace()\n",
        "\n",
        "        # MSE loss between 51 values of predicted_3d_pos and pose_3d_rel\n",
        "        loss_3d_pos =  mpjpe(predicted_3d_pos, pose_3d_rel)\n",
        "        epoch_loss_3d += pose_3d_rel.shape[0] * loss_3d_pos.item()\n",
        "\n",
        "        mpjpe_batch = mpjpe(predicted_3d_pos.detach().view(-1, 16, 3), pose_3d_rel.view(-1, 16, 3))\n",
        "        mpjpe_epoch = mpjpe_epoch + pose_3d_rel.shape[0] * mpjpe_batch\n",
        "\n",
        "        N += pose_3d_rel.shape[0]\n",
        "\n",
        "        loss_total = loss_3d_pos\n",
        "\n",
        "        if mode == 'train':\n",
        "            loss_total.backward()\n",
        "            optimiser.step()\n",
        "\n",
        "    mpjpe_epoch = mpjpe_epoch / N\n",
        "    epoch_loss_3d = epoch_loss_3d / N\n",
        "    elapsed = (time() - start_time) / 60\n",
        "\n",
        "    print('{}: [{:d}] time {:.2f} 3d_loss {:.3f} Mpjpe {:2f}'.format(\n",
        "        mode, epoch, elapsed, epoch_loss_3d, mpjpe_epoch * 1000))\n",
        "\n",
        "    result = dict()\n",
        "    result['mpjpe'] = mpjpe_epoch * 1000\n",
        "\n",
        "    return result \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZvAYtW2NnA2",
        "colab_type": "text"
      },
      "source": [
        "<font color=red>The following code is the starting point of execution. We start with creating data loader for train and test splits.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbmwJFfjNy14",
        "colab_type": "code",
        "outputId": "08372281-7914-4fc5-e0c7-df4b3eb279aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "args = easydict.EasyDict({'batch_size': 64,\n",
        "        'epochs': 5,\n",
        "        'learning_rate': 0.001,})\n",
        "# print(args)\n",
        "\n",
        "tr_dataset = PoseDataset(args, split='train')\n",
        "te_dataset = PoseDataset(args, split='test')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    tr_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        "    pin_memory=True,\n",
        "    drop_last=True\n",
        "    # worker_init_fn=worker_init_fn\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    te_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=1,\n",
        "    # worker_init_fn=worker_init_fn\n",
        ")\n",
        "\n",
        "num_joints_in = tr_dataset.poses_2d.shape[1]  # 17 in our case  \n",
        "in_features = tr_dataset.poses_2d.shape[2]  # 2 in our case x and y co-ordinates\n",
        "num_joints_out = tr_dataset.poses_3d.shape[1] - 1  # 17-1=16 in our case ignoring the root as prediction is root relative. \n",
        "# n_blocks = 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating train data loader\n",
            "\n",
            "Creating test data loader\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXdDilnJOD3t",
        "colab_type": "text"
      },
      "source": [
        "<font color=red>Next we create out 3D pose prediction model, define the optimiser and learning rate schedular.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxKafEUlOYu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_pose = PoseModel(num_joints_in, in_features, num_joints_out, \n",
        "                       dropout=0.25, channels=1024)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model_pose = model_pose.cuda()\n",
        "\n",
        "optimizer = optim.Adam(model_pose.parameters(), lr=args.learning_rate, amsgrad=True)\n",
        "schedular = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qZe8La7OevG",
        "colab_type": "text"
      },
      "source": [
        "<font color=red>Finally, we start our training and testing for 10 epochs.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqnkX5X9D9AA",
        "colab_type": "code",
        "outputId": "734fc16b-d602-47b3-bf7e-cd866fbb6830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "epoch = 1\n",
        "min_mpjpe = 999.0\n",
        "while epoch < args.epochs:\n",
        "    _ = run_epoch(epoch, args, model_pose, train_loader, optimizer, \n",
        "                  mode='train', viz_pred=False)\n",
        "    \n",
        "    result_test = run_epoch(epoch, args, model_pose, train_loader, optimizer, \n",
        "                            mode='test', viz_pred=False)\n",
        "\n",
        "    if result_test['mpjpe'] < min_mpjpe:\n",
        "        min_mpjpe = result_test['mpjpe']\n",
        "\n",
        "        torch.save(model_pose.state_dict(), 'checkpoint/model_best.pth')\n",
        "\n",
        "    epoch = epoch + 1\n",
        "\n",
        "    schedular.step()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 4877/4877 [00:38<00:00, 125.23it/s]\n",
            "  0%|          | 0/4877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: [1] time 0.65 3d_loss 0.599 Mpjpe 131.952850\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 4877/4877 [00:20<00:00, 239.17it/s]\n",
            "  0%|          | 0/4877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test: [1] time 0.34 3d_loss 0.314 Mpjpe 64.997078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 4877/4877 [00:38<00:00, 128.23it/s]\n",
            "  0%|          | 0/4877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: [2] time 0.63 3d_loss 0.350 Mpjpe 74.245750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 4877/4877 [00:20<00:00, 210.43it/s]\n",
            "  0%|          | 0/4877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test: [2] time 0.34 3d_loss 0.247 Mpjpe 50.947876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 4877/4877 [00:38<00:00, 126.11it/s]\n",
            "  0%|          | 0/4877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: [3] time 0.64 3d_loss 0.315 Mpjpe 66.411659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 4877/4877 [00:20<00:00, 239.00it/s]\n",
            "  0%|          | 0/4877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test: [3] time 0.34 3d_loss 0.230 Mpjpe 47.796196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 4877/4877 [00:38<00:00, 125.23it/s]\n",
            "  0%|          | 0/4877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: [4] time 0.65 3d_loss 0.296 Mpjpe 62.356483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 4877/4877 [00:20<00:00, 239.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test: [4] time 0.34 3d_loss 0.213 Mpjpe 43.838509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "477Gf-ESOuoe",
        "colab_type": "text"
      },
      "source": [
        "<font color=red>After the training is complete we visualize the predicted poses given a 2D input.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0fL2M1_OpG-",
        "colab_type": "code",
        "outputId": "88ae29ab-a6ff-4a30-d08c-ebf3fcb52b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# Visualizing Test predictions\n",
        " run_epoch(1, args, model_pose, test_loader, optimizer, mode='test', viz_pred=True) # The first parameter is set to a dummy value 1."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1700 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAEoCAYAAAAqrOTwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABeIuAAAF4i4AAAXvr/B1vrLt6scUkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m<ipython-input-6-1cc7e4acba36>\u001b[0m(37)\u001b[0;36mrun_epoch\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     35 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     36 \u001b[0;31m        \u001b[0;31m# MSE loss between 51 values of predicted_3d_pos and pose_3d_rel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 37 \u001b[0;31m        \u001b[0mloss_3d_pos\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmpjpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_3d_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose_3d_rel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     38 \u001b[0;31m        \u001b[0mepoch_loss_3d\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpose_3d_rel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_3d_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     39 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}